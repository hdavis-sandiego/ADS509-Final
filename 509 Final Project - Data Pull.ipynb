{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b2fa5a",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124b5c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/halledavis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import regex as re\n",
    "import glob\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import html\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from string import punctuation\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196bebc0",
   "metadata": {},
   "source": [
    "# Scraping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff997a",
   "metadata": {},
   "source": [
    "## Get Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a8811b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = {'year07':\"https://arlweb.msha.gov/fatals/indices/FABM2007.asp\",\n",
    "         'year06':\"https://arlweb.msha.gov/fatals/indices/FABM2006.asp\",\n",
    "         'year05':\"https://arlweb.msha.gov/fatals/indices/FABM2005.asp\",\n",
    "         'year04':\"https://arlweb.msha.gov/fatals/indices/FABM2004.HTM\",\n",
    "         'year03':\"https://arlweb.msha.gov/fatals/indices/FABM2003.HTM\",\n",
    "         'year02':\"https://arlweb.msha.gov/fatals/indices/FABM2002.HTM\",\n",
    "         'year01':\"https://arlweb.msha.gov/fatals/indices/FABM2001.HTM\",\n",
    "         'year00':\"https://arlweb.msha.gov/fatals/indices/FABM2000.HTM\",\n",
    "         'year99':\"https://arlweb.msha.gov/fatals/indices/FABM99.HTM\",\n",
    "         'year98':\"https://arlweb.msha.gov/fatals/indices/FABM98.HTM\",\n",
    "         'year97':\"https://arlweb.msha.gov/fatals/indices/FABM97.HTM\",\n",
    "         'year96':\"https://arlweb.msha.gov/fatals/indices/FABM96.HTM\",\n",
    "         'year95':\"https://arlweb.msha.gov/fatals/indices/FABM95.HTM\",\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e3ad3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started At: 2023-06-12 17:44:18.370796 \n",
      "Ended At: 2023-06-12 17:46:41.368368\n"
     ]
    }
   ],
   "source": [
    "report_pages = defaultdict(list)\n",
    "urls = []\n",
    "start_time = datetime.now()\n",
    "\n",
    "\n",
    "for year, year_page in years.items() :\n",
    "    r = requests.get(year_page)\n",
    "    time.sleep(5 + 10*random.random())\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    links = soup.find_all('a', href=True)\n",
    "    for link in links:\n",
    "        if '/FATALS/' and '/FTL' in link['href']:\n",
    "            urls.append(link.get('href'))\n",
    "            report_pages[year].append(link.get('href'))\n",
    "            \n",
    "end_time = datetime.now()\n",
    "print(\"Started At:\", start_time, \"\\nEnded At:\", end_time)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e01007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For year07 we have 32.\n",
      "The full pull will take for this year will take 0.09 hours.\n",
      "For year06 we have 26.\n",
      "The full pull will take for this year will take 0.07 hours.\n",
      "For year05 we have 35.\n",
      "The full pull will take for this year will take 0.1 hours.\n",
      "For year04 we have 26.\n",
      "The full pull will take for this year will take 0.07 hours.\n",
      "For year03 we have 26.\n",
      "The full pull will take for this year will take 0.07 hours.\n",
      "For year02 we have 40.\n",
      "The full pull will take for this year will take 0.11 hours.\n",
      "For year01 we have 28.\n",
      "The full pull will take for this year will take 0.08 hours.\n",
      "For year00 we have 41.\n",
      "The full pull will take for this year will take 0.11 hours.\n",
      "For year99 we have 53.\n",
      "The full pull will take for this year will take 0.15 hours.\n",
      "For year98 we have 51.\n",
      "The full pull will take for this year will take 0.14 hours.\n",
      "For year97 we have 61.\n",
      "The full pull will take for this year will take 0.17 hours.\n",
      "For year96 we have 46.\n",
      "The full pull will take for this year will take 0.13 hours.\n",
      "For year95 we have 53.\n",
      "The full pull will take for this year will take 0.15 hours.\n"
     ]
    }
   ],
   "source": [
    "for year, links in report_pages.items() : \n",
    "    print(f\"For {year} we have {len(links)}.\")\n",
    "    print(f\"The full pull will take for this year will take {round(len(links)*10/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "973c3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [i for i in urls if not ('19' in i)] ## limiting to links 2000-2007"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48c2316",
   "metadata": {},
   "source": [
    "## Scrape Text to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('C:\\\\Users\\\\halle.davis\\\\Downloads\\\\reports') ## Halle's work folder path\n",
    "os.chdir('/Users/halledavis/Desktop/reports') ## Halle's personal folder path\n",
    "#os.chdir('') ## Claire's folder path\n",
    "#os.chdir('') ## Summer's folder path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b69e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run on All Links\n",
    "## This will take an hour to run!!! (Lots of documents)\n",
    "\n",
    "url_stub = \"https://arlweb.msha.gov/\" \n",
    "start_time = datetime.now()\n",
    "\n",
    "total_pages = 0 ## used if we want to limit the report number for performance purposes\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "for x in urls :\n",
    "    #if total_pages == 22:   ## used if we want to limit the report number for performance purposes\n",
    "    #    break \n",
    "    name0 = x.replace('/', '')\n",
    "    name = name0.replace('.HTM', '')\n",
    "    name = name.replace('.asp', '')\n",
    "    filename = name+\".txt\"\n",
    "    if os.path.exists(filename):\n",
    "        file = open(filename, \"r+\")\n",
    "    else:\n",
    "        file = open(filename, \"w+\")\n",
    "    try:\n",
    "        soup = BeautifulSoup(requests.get(url_stub+x).content, \"html.parser\")    \n",
    "        time.sleep(5 + 10*random.random())\n",
    "        report = soup.get_text()\n",
    "        #title = soup.title.string\n",
    "        file.writelines(report)\n",
    "        time.sleep(5 + 10*random.random())\n",
    "        total_pages += 1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "end_time = datetime.now()\n",
    "print(\"Started At:\", start_time, \"\\nEnded At:\", end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8bd38",
   "metadata": {},
   "source": [
    "## Download Data to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(os.getcwd(), \"*.txt\"))\n",
    "start_time = datetime.now()\n",
    "\n",
    "reports = []\n",
    "\n",
    "for file_path in file_list:\n",
    "    with open(file_path) as f_input:\n",
    "        text = (f_input.read())\n",
    "        file_name = file_path.split(\"reports\")[-1]\n",
    "        reports.append(\n",
    "            {\n",
    "                'filename': file_name,\n",
    "                'alltext': text\n",
    "            }\n",
    "        )\n",
    "        \n",
    "data = pd.DataFrame(reports)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"Started At:\", start_time, \"\\nEnded At:\", end_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
