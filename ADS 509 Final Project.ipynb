{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b2fa5a",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124b5c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/halledavis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import regex as re\n",
    "import glob\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import html\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from string import punctuation\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196bebc0",
   "metadata": {},
   "source": [
    "# Scraping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff997a",
   "metadata": {},
   "source": [
    "## Get Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a8811b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = {'year07':\"https://arlweb.msha.gov/fatals/indices/FABM2007.asp\",\n",
    "         'year06':\"https://arlweb.msha.gov/fatals/indices/FABM2006.asp\",\n",
    "         'year05':\"https://arlweb.msha.gov/fatals/indices/FABM2005.asp\",\n",
    "         'year04':\"https://arlweb.msha.gov/fatals/indices/FABM2004.HTM\",\n",
    "         'year03':\"https://arlweb.msha.gov/fatals/indices/FABM2003.HTM\",\n",
    "         'year02':\"https://arlweb.msha.gov/fatals/indices/FABM2002.HTM\",\n",
    "         'year01':\"https://arlweb.msha.gov/fatals/indices/FABM2001.HTM\",\n",
    "         'year00':\"https://arlweb.msha.gov/fatals/indices/FABM2000.HTM\",\n",
    "         'year99':\"https://arlweb.msha.gov/fatals/indices/FABM99.HTM\",\n",
    "         'year98':\"https://arlweb.msha.gov/fatals/indices/FABM98.HTM\",\n",
    "         'year97':\"https://arlweb.msha.gov/fatals/indices/FABM97.HTM\",\n",
    "         'year96':\"https://arlweb.msha.gov/fatals/indices/FABM96.HTM\",\n",
    "         'year95':\"https://arlweb.msha.gov/fatals/indices/FABM95.HTM\",\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e3ad3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started At: 2023-06-12 17:44:18.370796 \n",
      "Ended At: 2023-06-12 17:46:41.368368\n"
     ]
    }
   ],
   "source": [
    "report_pages = defaultdict(list)\n",
    "urls = []\n",
    "start_time = datetime.now()\n",
    "\n",
    "\n",
    "for year, year_page in years.items() :\n",
    "    r = requests.get(year_page)\n",
    "    time.sleep(5 + 10*random.random())\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    links = soup.find_all('a', href=True)\n",
    "    for link in links:\n",
    "        if '/FATALS/' and '/FTL' in link['href']:\n",
    "            urls.append(link.get('href'))\n",
    "            report_pages[year].append(link.get('href'))\n",
    "            \n",
    "end_time = datetime.now()\n",
    "print(\"Started At:\", start_time, \"\\nEnded At:\", end_time)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e01007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For year07 we have 32.\n",
      "The full pull will take for this year will take 0.09 hours.\n",
      "For year06 we have 26.\n",
      "The full pull will take for this year will take 0.07 hours.\n",
      "For year05 we have 35.\n",
      "The full pull will take for this year will take 0.1 hours.\n",
      "For year04 we have 26.\n",
      "The full pull will take for this year will take 0.07 hours.\n",
      "For year03 we have 26.\n",
      "The full pull will take for this year will take 0.07 hours.\n",
      "For year02 we have 40.\n",
      "The full pull will take for this year will take 0.11 hours.\n",
      "For year01 we have 28.\n",
      "The full pull will take for this year will take 0.08 hours.\n",
      "For year00 we have 41.\n",
      "The full pull will take for this year will take 0.11 hours.\n",
      "For year99 we have 53.\n",
      "The full pull will take for this year will take 0.15 hours.\n",
      "For year98 we have 51.\n",
      "The full pull will take for this year will take 0.14 hours.\n",
      "For year97 we have 61.\n",
      "The full pull will take for this year will take 0.17 hours.\n",
      "For year96 we have 46.\n",
      "The full pull will take for this year will take 0.13 hours.\n",
      "For year95 we have 53.\n",
      "The full pull will take for this year will take 0.15 hours.\n"
     ]
    }
   ],
   "source": [
    "for year, links in report_pages.items() : \n",
    "    print(f\"For {year} we have {len(links)}.\")\n",
    "    print(f\"The full pull will take for this year will take {round(len(links)*10/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "973c3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [i for i in urls if not ('19' in i)] ## limiting to links 2000-2007"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48c2316",
   "metadata": {},
   "source": [
    "## Scrape Text to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('C:\\\\Users\\\\halle.davis\\\\Downloads\\\\reports') ## Halle's work folder path\n",
    "os.chdir('/Users/halledavis/Desktop/reports') ## Halle's personal folder path\n",
    "#os.chdir('') ## Claire's folder path\n",
    "#os.chdir('') ## Summer's folder path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b69e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run on All Links\n",
    "## This will take an hour to run!!! (Lots of documents)\n",
    "\n",
    "url_stub = \"https://arlweb.msha.gov/\" \n",
    "start_time = datetime.now()\n",
    "\n",
    "total_pages = 0 ## used if we want to limit the report number for performance purposes\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "for x in urls :\n",
    "    #if total_pages == 22:   ## used if we want to limit the report number for performance purposes\n",
    "    #    break \n",
    "    name0 = x.replace('/', '')\n",
    "    name = name0.replace('.HTM', '')\n",
    "    name = name.replace('.asp', '')\n",
    "    filename = name+\".txt\"\n",
    "    if os.path.exists(filename):\n",
    "        file = open(filename, \"r+\")\n",
    "    else:\n",
    "        file = open(filename, \"w+\")\n",
    "    try:\n",
    "        soup = BeautifulSoup(requests.get(url_stub+x).content, \"html.parser\")    \n",
    "        time.sleep(5 + 10*random.random())\n",
    "        report = soup.get_text()\n",
    "        #title = soup.title.string\n",
    "        file.writelines(report)\n",
    "        time.sleep(5 + 10*random.random())\n",
    "        total_pages += 1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "end_time = datetime.now()\n",
    "print(\"Started At:\", start_time, \"\\nEnded At:\", end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8bd38",
   "metadata": {},
   "source": [
    "## Download Data to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(os.getcwd(), \"*.txt\"))\n",
    "start_time = datetime.now()\n",
    "\n",
    "reports = []\n",
    "\n",
    "for file_path in file_list:\n",
    "    with open(file_path) as f_input:\n",
    "        text = (f_input.read())\n",
    "        file_name = file_path.split(\"reports\")[-1]\n",
    "        reports.append(\n",
    "            {\n",
    "                'filename': file_name,\n",
    "                'alltext': text\n",
    "            }\n",
    "        )\n",
    "        \n",
    "data = pd.DataFrame(reports)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"Started At:\", start_time, \"\\nEnded At:\", end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba301c5",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd21f5ea",
   "metadata": {},
   "source": [
    "### Get Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title'] = data.alltext.astype(str).str.extract(r': (.*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d06ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c632019",
   "metadata": {},
   "source": [
    "### Get Cause"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c26b576",
   "metadata": {},
   "source": [
    "#### Causes include\n",
    "ELECTRICAL - Accidents in which electric current is most directly responsible for the resulting accident.\n",
    "\n",
    "ENTRAPMENT - In accidents involving no injuries or nonfatal injuries which are not serious, entrapment of mine workers takes precedence over roof falls, explosives accidents, inundations, etc. If a roof fall results in an entrapment accident, the accident classification is ï¿½Entrapment.\n",
    "\n",
    "EXPLODING VESSELS UNDER PRESSURE - These are accidents caused by explosion of air hoses, air tanks, hydraulic lines, hydraulic hoses, and other accidents precipitated by exploding vessels.\n",
    "\n",
    "EXPLOSIVES AND BREAKING AGENTS - Accidents involving the detonation of manufactured explosives, Airdox, or Cardox, that can cause flying debris, concussive forces, or fumes.\n",
    "\n",
    "FALLING, ROLLING, OR SLIDING ROCK OR MATERIAL OF ANY KIND -Injuries caused directly by falling material require great care in classification. Remember that it is the accident we want to classify. If material was set in motion by machinery, haulage equipment, or hand tools, or while material is being handled or disturbed, etc., charge the force that set the material in motion. For example, where a rock was pushed over a highwall by a dozer and the rock hit another rock which struck and injured a worker - charge the accident to the dozer. Charge the accident to that which most directly caused the resulting accident. Without the dozer, there would have been no resulting accident. This includes accidents caused by improper blocking of equipment under repair or inspection.\n",
    "\n",
    "FALL OF FACE, RIB, SIDE OR HIGHWALL - Accidents in this classification include falls of material (from in-place) while barring down or placing props; also pressure bumps and bursts. Since pressure bumps and bursts which cause accidents are infrequent, they are not given a separate category. Not included are accidents in which the motion of machinery or haulage equipment caused the fall either directly or by knocking out support; such accidents are classified as machinery or haulage, whichever is appropriate.\n",
    "\n",
    "FALL OF ROOF OR BACK - Underground accidents which include falls while barring down or placing props; also pressure bumps and bursts. Not included are accidents in which the motion of machinery or haulage equipment caused the fall either directly or by knocking out support; such falls are classified as machinery or haulage, whichever is appropriate.\n",
    "\n",
    "FIRE - In underground mines, an unplanned fire not extinguished within 10 minutes of discovery; in surface mines and surface areas of underground mines, an unplanned fire not extinguished within 30 minutes of discovery;\n",
    "\n",
    "HANDLING MATERIAL - (Lifting, pulling, pushing, shoveling material.) The material may be in bags or boxes, or loose sand, coal, rock, timber, etc. The accident must have been most directly caused by handling material.\n",
    "\n",
    "HAND TOOLS - Accidents related to non-powered tools when being used as hand tools. Do not include electric tools or air-powered tools.\n",
    "\n",
    "HOISTING - Damage to hoisting equipment in a shaft or slope which endangers an individual or interferes with use of the equipment for more than 30 minutes. Hoisting may also be the classification where a victim was injured by hoisting equipment but there was no damage to the equipment. Accidents involving cages, skips, buckets, or elevators. The accident results from the action, motion, or failure of the hoisting equipment or mechanism. Included is equipment such as derricks and cranes only when used in shaft sinking; suspended work platforms in shafts; mine cars being lowered or raised by hoisting equipment on slopes or inclines; a skip squeezed between timbers resulting in an accident; or an ore bucket tipped for any reason causing an accident.\n",
    "\n",
    "IGNITION OR EXPLOSION OF GAS OR DUST - Accidents resulting as a consequence of the ignition or explosion of gas or dust. Included are exploding gasoline vapors, space heaters, or furnaces.\n",
    "Methane Ignition - A methane ignition occurs when methane burns without producing destructive forces. Damage resulting from an ignition is limited to that caused by flame and heat. Personnel in the immediate vicinity of an ignition may be burned and line brattice or other materials in close proximity may be discolored, melted or burned. Ignitions generally involve small quantities of methane and are usually confined to a small area; however, in the case of methane roof layering, flame spread may be more extensive.\n",
    "Methane Explosion - A methane explosion occurs when methane is ignited and burns violently. The flame of the explosion accelerates rapidly, heating the environment and causing destructive forces. Evidence of the destructive forces may be manifest on victims, equipment, structures, etc. Witnesses to an explosion may hear the noise generated by the resulting sound pressure wave.\n",
    "\n",
    "IMPOUNDMENT - An unstable condition at an impoundment, refuse pile, or culm bank which requires emergency action in order to prevent failure, or which causes individuals to evacuate an area. Also the failure of an impoundment, refuse pile, or culm bank.\n",
    "\n",
    "INUNDATION - An unplanned inundation of a mine by a liquid or gas. The mine may be either a surface or underground operation.\n",
    "\n",
    "MACHINERY - Accidents that result from the action or motion of machinery or from failure of component parts. Included are all electric and air-powered tools and mining machinery such as drills, tuggers, slushers, draglines, power shovels, loading machines, compressors, etc. Include derricks and cranes except when they are used in shaft sinking (see HOISTING) or mobile cranes traveling with a load (see POWERED HAULAGE).\n",
    "\n",
    "NON-POWERED HAULAGE - Accidents related to motion of non-powered haulage equipment. Included are accidents involving wheelbarrows, manually pushed mine cars and trucks, etc.\n",
    "\n",
    "POWERED HAULAGE - Haulage includes motors and rail cars, conveyors, belt feeders, longwall conveyors, bucket elevators, vertical manlifts, self-loading scrapers or pans, shuttle cars, haulage trucks, front-end loaders, load-haul- dumps, forklifts, cherry pickers, mobile cranes if traveling with a load, etc. The accident is caused by the motion of the haulage unit. Include accidents that are caused by an energized or moving unit or failure of component parts. If a car dropper suffers an injury as a result of falling from a moving car, charge the accident to haulage.\n",
    "\n",
    "SLIP OR FALL OF PERSON - Includes slips or falls from an elevated position or at the same level while getting on or off machinery or haulage equipment that is not moving. Also includes slips or falls while servicing or repairing equipment or machinery. Includes stepping in a hole.\n",
    "\n",
    "STEPPING OR KNEELING ON OBJECT - Accidents are classified in this category only where the object stepped or kneeled on contributed most directly to the accident.\n",
    "\n",
    "STRIKING OR BUMPING - This classification is restricted to those accidents in which an individual, while moving about, strikes or bumps an object but is not handling material, using hand tools, or operating equipment.\n",
    "\n",
    "OTHER - Accidents not elsewhere classified. This is a last resort category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cause Keywords\n",
    "\n",
    "electric = ['electric', 'electrical']\n",
    "entrapment = ['entrapment']\n",
    "explodingvessels = ['vessels', 'pressure']\n",
    "explosives = ['explosives', 'agents']\n",
    "fallingmaterial = ['material', 'rock']\n",
    "fallofface = ['face', 'rib', 'side', 'highwall']\n",
    "fallofroof = ['roof', 'back']\n",
    "fire = ['fire']\n",
    "handlingmaterial = ['handling']\n",
    "handtools = ['hand', 'handtools']\n",
    "hoisting = ['hoist', 'hositing']\n",
    "ignition = ['ignition', 'gas', 'dust', 'ignition/explosion', 'methane']\n",
    "impoundment = ['impoundment']\n",
    "inundation = ['inundation']\n",
    "machinery = ['machinery']\n",
    "nonpoweredhaulage = ['non-powered']\n",
    "poweredhaulage = ['powered']\n",
    "slipfall = ['slip', 'fall', 'slip/fall', '/fall']\n",
    "stepping = ['stepping', 'kneeling']\n",
    "striking = ['striking', 'bumping']\n",
    "other = ['other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causeclassifier(sentence):\n",
    "    if any(word in electric for word in sentence.lower().split()):\n",
    "        return 'Electric'\n",
    "    elif any(word in entrapment for word in sentence.lower().split()):\n",
    "        return 'Entrapment'\n",
    "    elif any(word in explodingvessels for word in sentence.lower().split()):\n",
    "        return 'Exploding Vessels'\n",
    "    elif any(word in explosives for word in sentence.lower().split()):\n",
    "        return 'Explosives'\n",
    "    elif any(word in fallingmaterial for word in sentence.lower().split()):\n",
    "        return 'Falling Material'\n",
    "    elif any(word in fallofface for word in sentence.lower().split()):\n",
    "        return 'Fall of Face'\n",
    "    elif any(word in fallofroof for word in sentence.lower().split()):\n",
    "        return 'Fall of Roof'\n",
    "    elif any(word in fire for word in sentence.lower().split()):\n",
    "        return 'Fire'\n",
    "    elif any(word in handlingmaterial for word in sentence.lower().split()):\n",
    "        return 'Handling Material'\n",
    "    elif any(word in handtools for word in sentence.lower().split()):\n",
    "        return 'Hand Tools'\n",
    "    elif any(word in hoisting for word in sentence.lower().split()):\n",
    "        return 'Hoisting'\n",
    "    elif any(word in ignition for word in sentence.lower().split()):\n",
    "        return 'Ignition/Explosion'\n",
    "    elif any(word in inundation for word in sentence.lower().split()):\n",
    "        return 'Inundation'\n",
    "    elif any(word in machinery for word in sentence.lower().split()):\n",
    "        return 'Machinery'\n",
    "    elif any(word in nonpoweredhaulage for word in sentence.lower().split()):\n",
    "        return 'Non-Powered Haulage'\n",
    "    elif any(word in poweredhaulage for word in sentence.lower().split()):\n",
    "        return 'Powered Haulage'\n",
    "    elif any(word in slipfall for word in sentence.lower().split()):\n",
    "        return 'Slip/Fall'\n",
    "    elif any(word in stepping for word in sentence.lower().split()):\n",
    "        return 'Stepping'\n",
    "    elif any(word in striking for word in sentence.lower().split()):\n",
    "        return 'Striking'\n",
    "    elif any(word in other for word in sentence.lower().split()):\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39522872",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cause'] = data['title'].astype(str).apply(causeclassifier)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a07a19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83beed31",
   "metadata": {},
   "source": [
    "### Get Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c936a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['year']  = data.alltext.astype(str).str.extract(r'(200\\d)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b5c9d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26ca5c8",
   "metadata": {},
   "source": [
    "### Clean & Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef66a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return re.findall(r'[\\w-]*\\p{L}[\\w-]*', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a25796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop(tokens):\n",
    "    return [t for t in tokens if t.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e271b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [str.lower, tokenize, remove_stop]\n",
    "def prepare(text, pipeline):\n",
    "    tokens = text\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce87e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # convert html escapes like &amp; to characters.\n",
    "    text = html.unescape(text)\n",
    "    # tags like <tab>\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    # standalone sequences of specials, matches &# but not #cool\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text) # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042b91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data['alltext'].apply(prepare, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cleantext\"] = data[\"alltext\"].apply(clean)\n",
    "data[\"cleantext\"] = data[\"cleantext\"].apply(str.lower)\n",
    "data[\"cleantext\"] = data[\"cleantext\"].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2555135",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20857e82",
   "metadata": {},
   "source": [
    "### Get Text by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c01a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Overview\n",
    "\n",
    "data['overview']  = data.cleantext.astype(str).str.extract(r'overview(.*) general info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fbdd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get General Information\n",
    "\n",
    "data['geninfo']  = data.cleantext.astype(str).str.extract(r'information(.*)description of') #sometimes its \"the accident\" and sometimes its just accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of Accident\n",
    "\n",
    "data['description']  = data.cleantext.astype(str).str.extract(r'description of(.*)investigation of') #sometimes its \"the accident\" and sometimes its just accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0640ea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Info\n",
    "# contains information from the investigation, root cause, and discussion segments\n",
    "# did not separate because headers vary in order and presence, so was difficult to parse out those exact sections\n",
    "\n",
    "data['otherinfo']  = data.cleantext.astype(str).str.extract(r'investigation of(.*)conclusion') #sometimes its \"the accident\" and sometimes its just accident\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1472b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Failed Attempt to Pull Out Investigation Only -- doesn't take into consideration ordering differences\n",
    "# investigation = []\n",
    "\n",
    "#for value in data['cleantext']:\n",
    "#    if 'root cause analysis' in value:\n",
    "#        investigation.append(re.findall(r'investigation of(.*)root cause analysis', value))\n",
    "#    else:\n",
    "#        investigation.append(re.findall(r'investigation of(.*) discussion', value))\n",
    "\n",
    "# data['investigation'] = investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['conclusion']  = data.cleantext.astype(str).str.extract(r'conclusion(.*)enforcement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99414f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['enforcement']  = data.cleantext.astype(str).str.extract(r'enforcement action(.*)appendix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10243278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['overview'] = data['overview'].astype(str)\n",
    "data['overview_tokens'] = data['overview'].apply(prepare, pipeline=pipeline)\n",
    "\n",
    "data['geninfo'] = data['geninfo'].astype(str)\n",
    "data['geninfo_tokens'] = data['geninfo'].apply(prepare, pipeline=pipeline)\n",
    "\n",
    "data['otherinfo'] = data['otherinfo'].astype(str)\n",
    "data['otherinfo_tokens'] = data['otherinfo'].apply(prepare, pipeline=pipeline)\n",
    "\n",
    "data['conclusion'] = data['conclusion'].astype(str)\n",
    "data['conclusion_tokens'] = data['conclusion'].apply(prepare, pipeline=pipeline)\n",
    "\n",
    "data['enforcement'] = data['enforcement'].astype(str)\n",
    "data['enforcement_tokens'] = data['enforcement'].apply(prepare, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09291551",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5920d6",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e436d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :    \n",
    "    counter = Counter()\n",
    "    tokens.map(counter.update)\n",
    "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
    "    \n",
    "    counter_df = pd.DataFrame.from_dict(counter, orient='index').reset_index()\n",
    "    \n",
    "    num_tokens = sum(freq_df['freq'])\n",
    "    num_unique_tokens = freq_df.shape[0]\n",
    "    lexical_diversity = num_unique_tokens / num_tokens\n",
    "    num_characters = sum((counter_df['index'].str.len()) * counter_df[0])\n",
    "    \n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "        print(f\"The top 5 most common words are\")\n",
    "        print(counter.most_common(5))\n",
    "        \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_stats(data[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524dc41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48d600a7",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d1d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
